{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('JobKorea_convert.pickle', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(rows):\n",
    "    rowlist = [i for i in rows]\n",
    "    Q = []\n",
    "    content = []\n",
    "    comment = []\n",
    "    for row in rowlist:\n",
    "        Q_ = row[0]\n",
    "        content_ = row[1]\n",
    "        comment_ = row[2]\n",
    "        Q.append(Q_)\n",
    "        content.append(content_)\n",
    "        comment.append(comment_)\n",
    "    \n",
    "    return Q, content, comment\n",
    "\n",
    "def preprocessing_applicatInfo(row):\n",
    "    row = row.replace('\\r','').replace('\\n','')\n",
    "    row = re.sub(' +', ' ', row)\n",
    "    return row\n",
    "\n",
    "\n",
    "def preprocessing_content(rows, type_='content'):\n",
    "    contents = []\n",
    "    for row in rows:\n",
    "        if type_ == 'content':\n",
    "            row = re.sub('아쉬운점 [0-9]','', row)\n",
    "            row = re.sub('좋은점 [0-9]','', row)\n",
    "            row = row[0:re.search('글자수', row).start()-1]\n",
    "        try:\n",
    "            row = row.replace('\\r','').replace('\\n','')\n",
    "            row = re.sub(' +', ' ', row)\n",
    "        except:\n",
    "            pass\n",
    "        contents.append(row)\n",
    "    return contents\n",
    "\n",
    "\n",
    "df['Question'] = df['paper'].map(get_content).map(lambda x:x[0])\n",
    "df['content'] = df['paper'].map(get_content).map(lambda x:x[1])\n",
    "df['comment'] = df['paper'].map(get_content).map(lambda x:x[2])\n",
    "df = df.drop('paper', axis=1)\n",
    "\n",
    "df['applicant_info'] = df['applicant_info'].map(preprocessing_applicatInfo)\n",
    "\n",
    "df['content'] = df['content'].map(preprocessing_content)\n",
    "df['comment'] = df['comment'].map(lambda x: preprocessing_content(x, type_='comment'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('JobKorea_preprocessd.csv', encoding='utf-8-sig')\n",
    "# with open(\"JobKorea_preprocessd.pickle\",\"wb\") as fw:\n",
    "#     pickle.dump(df, fw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drop 149\n",
    "* 길이가 149이하인 답변은 삭제(질문, 전문가 조언 포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"JobKorea_preprocessd.pickle\", 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeup149(rows):\n",
    "    AremainList = []\n",
    "    BremainList = []\n",
    "    CremainList = []\n",
    "    for index, row in enumerate(rows['content']):\n",
    "        if len(row) >= 149:\n",
    "            AremainList.append(rows['Question'][index])\n",
    "            BremainList.append(rows['content'][index])\n",
    "            CremainList.append(rows['comment'][index])\n",
    "\n",
    "    return pd.Series([AremainList,BremainList,CremainList], index=['Question','content','comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Question','content','comment']] = df[['Question','content','comment']].apply(makeup149, axis=1)\n",
    "\n",
    "df = df[df['content'].apply(lambda x: True if x else False)]\n",
    "# content가 빈 리스트인 row 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('JobKorea_dropped.csv', encoding='utf-8-sig')\n",
    "# with open(\"JobKorea_dropped.pickle\",\"wb\") as fw:\n",
    "#     pickle.dump(df, fw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# content 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"JobKorea_dropped.pickle\", 'rb') as f:\n",
    "#     df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('JobKorea_dropped(수기수정 및 중복제거 및 소제목제거).csv',\n",
    "                encoding='cp949', index_col=0)\n",
    "\n",
    "df = df.dropna(how='all')\n",
    "df.index = df.index.astype(int)\n",
    "\n",
    "df['Question'] = df['Question'].map(eval)\n",
    "df['content'] = df['content'].map(eval)\n",
    "df['comment'] = df['comment'].map(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 소제목 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropSubhead(df):\n",
    "    content = df['content'].to_list()\n",
    "    regex=\"\\[.*\\]|\\s-\\s.*\" #[]\n",
    "    regex1=\"\\<.*\\>|\\s-\\s.*\"#<>\n",
    "    regex2='\\\".*\\\"|\\s-\\s.*' #\"\"\n",
    "    regex3=\"\\“.*\\”|\\s-\\s.*\" #“”\n",
    "    regex4=\"\\<<.*\\>>|\\s-\\s.*\" #<<>>\n",
    "    regex5=\"▶▶.*◀◀|\\s-\\s.*\" #▶▶ ◀◀\n",
    "    regex6=\"◆.*◆|\\s-\\s.*\" #◆ ◆\n",
    "\n",
    "    for i,value in enumerate(content):\n",
    "        for j, value2 in enumerate(value):\n",
    "            text = re.sub(regex,'',\"\".join(value2)[0:100])\n",
    "            text = re.sub(regex1,'',text)\n",
    "            text = re.sub(regex2,'',text)\n",
    "            text = re.sub(regex3,'',text)\n",
    "            text = re.sub(regex4,'',text)\n",
    "            text = re.sub(regex5,'',text)\n",
    "            text = re.sub(regex6,'',text)\n",
    "            text = text+value2[100:]\n",
    "            text = re.sub('①','1.',text)\n",
    "            text = re.sub('②','2.',text)\n",
    "            text = re.sub('③','3.',text)\n",
    "            text = re.sub('[\\\\#■]','',text) # \\, # 제거\n",
    "            content[i][j]= text\n",
    "    df['content'] = content\n",
    "    return df\n",
    "\n",
    "df = dropSubhead(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영어로 작성된 자소서 drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEng(rows):\n",
    "    for row in rows:\n",
    "        for i in row:\n",
    "            if len(re.findall('[a-z]',i))/len(i) > 0.3:\n",
    "                return True\n",
    "            else: return False\n",
    "\n",
    "df = df[~df[['content']].apply(isEng,axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('JobKorea_processed.csv', encoding='utf-8-sig')\n",
    "with open(\"JobKorea_processed.pickle\",\"wb\") as fw:\n",
    "    pickle.dump(df, fw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
